{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix,accuracy_score, roc_curve, auc, precision_recall_curve\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence,pack_padded_sequence, pad_packed_sequence\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = 5,2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "train_data = torch.load('train_data.pt')\n",
    "test_data = torch.load('test_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class Covid_19(Dataset):\n",
    "    def __init__(self,dataList):\n",
    "        self.data_list = dataList\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ptid = self.data_list[idx][0]\n",
    "        sample = self.data_list[idx][1]\n",
    "        return sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class Sampler(torch.utils.data.sampler.Sampler):\n",
    "\n",
    "    def __init__(self, dataset, indices=None, num_samples=None, callback_get_label=None):\n",
    "\n",
    "        self.indices = list(range(len(dataset))) \\\n",
    "            if indices is None else indices\n",
    "        self.callback_get_label = callback_get_label\n",
    "\n",
    "        self.num_samples = len(self.indices) \\\n",
    "            if num_samples is None else num_samples\n",
    "            \n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "                \n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)]\n",
    "                   for idx in self.indices]\n",
    "        self.weights = torch.DoubleTensor(weights)\n",
    "\n",
    "    def _get_label(self, dataset, idx):\n",
    "        return dataset[idx][-1]\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "            self.weights, self.num_samples, replacement=True))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def pad_collate(batch):\n",
    "    (pt_problem_batch, pt_lab_batch,pt_diag_batch,pt_orders_batch,pt_medAdmin_batch,pt_demo_batch,label_batch) = zip(*batch)\n",
    "    pt_demo_batch =torch.stack([item[5] for item in batch])\n",
    "    label_batch =[item[6] for item in batch]\n",
    "    max_problem = np.max(np.array([[DB.size(0),DB.size(1)]for DB in pt_problem_batch]),axis=0)\n",
    "    max_lab = np.max(np.array([[DB.size(0),DB.size(1)]for DB in pt_lab_batch]),axis=0)\n",
    "    max_diag = np.max(np.array([[DB.size(0),DB.size(1)]for DB in pt_diag_batch]),axis=0)\n",
    "    max_orders= np.max(np.array([[DB.size(0),DB.size(1)]for DB in pt_orders_batch]),axis=0)\n",
    "    max_medAdmin= np.max(np.array([[DB.size(0),DB.size(1)]for DB in pt_medAdmin_batch]),axis=0)\n",
    "    problem_batch = torch.stack([\n",
    "        F.pad(DB, [0, max_problem[1] - DB.size(1), 0, max_problem[0] - DB.size(0)])\n",
    "        for DB in pt_problem_batch\n",
    "    ])\n",
    "    lab_batch = torch.stack([\n",
    "        F.pad(DB, [0, max_lab[1] - DB.size(1), 0, max_lab[0] - DB.size(0)])\n",
    "        for DB in pt_lab_batch\n",
    "        ])\n",
    "    diag_batch = torch.stack([\n",
    "        F.pad(DB, [0, max_diag[1] - DB.size(1), 0, max_diag[0] - DB.size(0)])\n",
    "        for DB in pt_diag_batch\n",
    "        ])\n",
    "    orders_batch = torch.stack([\n",
    "        F.pad(DB, [0, max_orders[1] - DB.size(1), 0, max_orders[0] - DB.size(0)])\n",
    "        for DB in pt_orders_batch\n",
    "        ])\n",
    "    medAdmin_batch = torch.stack([\n",
    "        F.pad(DB, [0, max_medAdmin[1] - DB.size(1), 0, max_medAdmin[0] - DB.size(0)])\n",
    "        for DB in pt_medAdmin_batch\n",
    "        ])\n",
    "\n",
    "    return problem_batch, lab_batch, diag_batch, orders_batch, medAdmin_batch, pt_demo_batch,label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset=Covid_19(train_data)\n",
    "validation_dataset = Covid_19(test_data)\n",
    "trainSampler = Sampler(train_dataset)\n",
    "dataloader = DataLoader(train_dataset, batch_size=24,\n",
    "                        shuffle=False, num_workers=0,drop_last=True,collate_fn=pad_collate,sampler = trainSampler)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=24,\n",
    "                        shuffle=False, num_workers=0,drop_last=True,collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBNet(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(DBNet, self).__init__()\n",
    "        \n",
    "        ####vars to set\n",
    "        dropout_GRU = 0.5\n",
    "        hidden_size=512\n",
    "        no_GRU_layers=4\n",
    "        output_size = 2\n",
    "        GRU_input_size = 376 \n",
    "        no_hops = 8\n",
    "        \n",
    "        \n",
    "        ###(kernel_size,in_channel,out_channel, stride,pad)  \n",
    "        problem_kernels = [(7,1,8,2,0),(5,8,8,2,0),(3,8,1,1,0)]\n",
    "        lab_kernels = [(19,1,8,2,0),(15,8,8,2,0),(11,8,8,2,0),(7,8,8,2,0),(4,8,8,2,0),(3,8,1,2,1)]\n",
    "        diag_kernels =  [(11,1,8,2,0),(7,8,8,2,0),(5,8,8,2,0),(3,8,1,2,1)]\n",
    "        orders_kernels = [(19,1,8,2,0),(15,8,8,2,0),(11,8,8,2,0),(7,8,8,2,0),(4,8,8,2,0),(3,8,1,2,1)]\n",
    "        medAdmin_kernels = [(19,1,8,2,0),(15,8,8,2,0),(11,8,8,2,0),(7,8,8,2,0),(4,8,8,2,0),(3,8,1,2,1)]\n",
    "\n",
    "        self.problem_layers = nn.ModuleList()\n",
    "        self.lab_layers = nn.ModuleList()\n",
    "        self.diag_layers = nn.ModuleList()\n",
    "        self.orders_layers = nn.ModuleList()\n",
    "        self.medAdmin_layers = nn.ModuleList()\n",
    "\n",
    "        \n",
    "        self.make_encoder_block(problem_kernels,self.problem_layers)\n",
    "        self.make_encoder_block(lab_kernels,self.lab_layers)\n",
    "        self.make_encoder_block(diag_kernels,self.diag_layers)\n",
    "        self.make_encoder_block(orders_kernels,self.orders_layers)\n",
    "        self.make_encoder_block(medAdmin_kernels,self.medAdmin_layers)\n",
    "\n",
    "        self.GRU = nn.GRU(GRU_input_size, hidden_size, no_GRU_layers, dropout=dropout_GRU,\n",
    "                                         batch_first=True, bias=False, bidirectional=True)\n",
    "        self.GRU_dropout = nn.Dropout(p=dropout_GRU)\n",
    "        self.conv_att = nn.Conv1d(in_channels=1, out_channels=no_hops, kernel_size=hidden_size * 2, stride=1)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size * 2 * no_hops + 296, output_size, bias=False)\n",
    "\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Hardtanh(0, 1)\n",
    "        self.init_weights()\n",
    "        self.no_hops = no_hops\n",
    "        self.hidden_size = hidden_size \n",
    "        self.output_size = output_size\n",
    "        self.no_GRU_layers = no_GRU_layers\n",
    "\n",
    "        \n",
    "    def make_encoder_block(self,kernel_list,layer_list):\n",
    "        for i,kernels in enumerate(kernel_list):\n",
    "            layer_list.append(nn.Conv1d(in_channels=kernels[1],\n",
    "                                        out_channels=kernels[2],\n",
    "                                        kernel_size=kernels[0],\n",
    "                                        stride=kernels[3],\n",
    "                                        padding=kernels[4]))\n",
    "            if i <len(layer_list)-1:\n",
    "                layer_list.append(nn.ReLU())\n",
    "            layer_list.append(nn.Dropout(p=0.3))\n",
    "        layer_list.append(nn.AdaptiveAvgPool1d(1))\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Conv1d):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def problem_encoder(self, problem):\n",
    "        encoded_problems=[]\n",
    "        for i in range(problem.size(1)):\n",
    "            for j,layer in enumerate(self.problem_layers):\n",
    "                if j==0:\n",
    "                    out = layer(torch.unsqueeze(problem[:,i],dim=1))\n",
    "                else:\n",
    "                    out =layer(out)\n",
    "            encoded_problems.append(out)\n",
    "        encoded_problems = torch.stack(encoded_problems)\n",
    "        encoded_problems = torch.squeeze(encoded_problems, dim=3)\n",
    "        encoded_problems =  torch.transpose(encoded_problems, 0, 1)\n",
    "        encoded_problems = torch.transpose(encoded_problems, 1, 2)\n",
    "        encoded_problems = self.tanh(encoded_problems)\n",
    "        encoded_problems = torch.bmm(encoded_problems, problem)\n",
    "        encoded_problems = torch.squeeze(encoded_problems, dim=1)\n",
    "        return encoded_problems\n",
    "    \n",
    "    def lab_encoder(self, lab):\n",
    "        encoded_DAMs=[]\n",
    "        for i in range(lab.size(1)):\n",
    "            for j,layer in enumerate(self.lab_layers):\n",
    "                if j==0:\n",
    "                    out = layer(torch.unsqueeze(lab[:,i],dim=1))\n",
    "                else:\n",
    "                    out =layer(out)\n",
    "            encoded_DAMs.append(out)\n",
    "        encoded_DAMs = torch.stack(encoded_DAMs)\n",
    "        encoded_DAMs = torch.squeeze(encoded_DAMs, dim=3)\n",
    "        encoded_DAMs = torch.transpose(encoded_DAMs, 0, 1)\n",
    "        encoded_DAMs = torch.transpose(encoded_DAMs, 1, 2)\n",
    "        encoded_DAMs = self.tanh(encoded_DAMs)\n",
    "        encoded_DAMs = torch.bmm(encoded_DAMs, lab)\n",
    "        encoded_DAMs = torch.squeeze(encoded_DAMs, dim=1)\n",
    "        return encoded_DAMs\n",
    "    \n",
    "    def diag_encoder(self, diag):\n",
    "        encoded_DPCs=[]\n",
    "        for i in range(diag.size(1)):\n",
    "            for j,layer in enumerate(self.diag_layers):\n",
    "                if j==0:\n",
    "                    out = layer(torch.unsqueeze(diag[:,i],dim=1))\n",
    "                else:\n",
    "                    out =layer(out)\n",
    "            encoded_DPCs.append(out)\n",
    "        encoded_DPCs = torch.stack(encoded_DPCs)\n",
    "        encoded_DPCs = torch.squeeze(encoded_DPCs, dim=3)\n",
    "        encoded_DPCs =  torch.transpose(encoded_DPCs, 0, 1)\n",
    "        encoded_DPCs = torch.transpose(encoded_DPCs, 1, 2)\n",
    "        encoded_DPCs = self.tanh(encoded_DPCs)\n",
    "        encoded_DPCs = torch.bmm(encoded_DPCs, diag)\n",
    "        encoded_DPCs = torch.squeeze(encoded_DPCs, dim=1)\n",
    "        return encoded_DPCs\n",
    "    \n",
    "    def orders_encoder(self, orders):\n",
    "        encoded_orderss = []\n",
    "        for i in range(orders.size(1)):\n",
    "            for j,layer in enumerate(self.orders_layers):\n",
    "                if j==0:\n",
    "                    out = layer(torch.unsqueeze(orders[:,i],dim=1))\n",
    "                else:\n",
    "                    out =layer(out)\n",
    "            encoded_orderss.append(out)\n",
    "        encoded_orderss = torch.stack(encoded_orderss)\n",
    "        encoded_orderss = torch.squeeze(encoded_orderss, dim=3)\n",
    "        encoded_orderss =  torch.transpose(encoded_orderss, 0, 1)\n",
    "        encoded_orderss = torch.transpose(encoded_orderss, 1, 2)\n",
    "        encoded_orderss = self.tanh(encoded_orderss)\n",
    "        encoded_orderss = torch.bmm(encoded_orderss, orders)\n",
    "        encoded_orderss = torch.squeeze(encoded_orderss, dim=1)\n",
    "        return encoded_orderss\n",
    "    \n",
    "    def medAdmin_encoder(self, medAdmin):\n",
    "        encoded_medAdmins = []\n",
    "        for i in range(medAdmin.size(1)):\n",
    "            for j,layer in enumerate(self.medAdmin_layers):\n",
    "                if j==0:\n",
    "                    out = layer(torch.unsqueeze(medAdmin[:,i],dim=1))\n",
    "                else:\n",
    "                    out =layer(out)\n",
    "            encoded_medAdmins.append(out)\n",
    "        encoded_medAdmins = torch.stack(encoded_medAdmins)\n",
    "        encoded_medAdmins = torch.squeeze(encoded_medAdmins, dim=3)\n",
    "        encoded_medAdmins =  torch.transpose(encoded_medAdmins, 0, 1)\n",
    "        encoded_medAdmins = torch.transpose(encoded_medAdmins, 1, 2)\n",
    "        encoded_medAdmins = self.tanh(encoded_medAdmins)\n",
    "        encoded_medAdmins = torch.bmm(encoded_medAdmins, medAdmin)\n",
    "        encoded_medAdmins = torch.squeeze(encoded_medAdmins, dim=1)\n",
    "        return encoded_medAdmins\n",
    "    \n",
    "    \n",
    "    def init_GRU(self, batch_size):\n",
    "        self.weight = next(self.parameters()).data\n",
    "        init_state = (Variable(self.weight.new(self.no_GRU_layers * 2, batch_size, self.hidden_size).zero_()))\n",
    "        return init_state\n",
    "\n",
    "    \n",
    "    def GRU_Decoder(self, inputs,batch_size):\n",
    "        inputs = self.GRU_dropout(inputs)\n",
    "        init_state = self.init_GRU(batch_size)\n",
    "        outputs, states = self.GRU(inputs, init_state)\n",
    "        return outputs,states\n",
    "    \n",
    "\n",
    "    def Self_Attention(self, hidden_states, batch_size):\n",
    "        Attention_list = []\n",
    "        for i in range(5):\n",
    "            m1 = self.conv_att(torch.unsqueeze(hidden_states[:, i], dim=1))\n",
    "            Attention_list.append(torch.squeeze(m1, dim=2))\n",
    "        Attention_list = torch.stack(Attention_list, dim=2)\n",
    "        Attention_hops = []\n",
    "        for i in range(self.no_hops):\n",
    "            attention_single = self.softmax(Attention_list[:, i])\n",
    "            Attention_hops.append(attention_single)\n",
    "        Attention_hops = torch.stack(Attention_hops, dim=1)\n",
    "        output = torch.bmm(Attention_hops, hidden_states)\n",
    "        output = output.view(batch_size, -1)\n",
    "        return output\n",
    "\n",
    "    def forward(self,problem, lab, diag, orders,medAdmin,pt_demo,batch_size):\n",
    "        encoded_problems = self.problem_encoder(problem)\n",
    "        encoded_labs = self.lab_encoder(lab)\n",
    "        encoded_diags = self.diag_encoder(diag)\n",
    "        encoded_orderss = self.orders_encoder(orders)\n",
    "        encoded_medAdmins = self.medAdmin_encoder(medAdmin)\n",
    "        GRU_input=pad_sequence([torch.transpose(encoded_problems, 0, 1),torch.transpose(encoded_labs, 0, 1),\n",
    "                                torch.transpose(encoded_diags, 0, 1),torch.transpose(encoded_orderss, 0, 1),\n",
    "                                torch.transpose(encoded_medAdmins, 0, 1)\n",
    "                               ])\n",
    "        GRU_input = torch.transpose(GRU_input, 0, 2)\n",
    "        outputs_GRU,states_GRU = self.GRU_Decoder(GRU_input, batch_size)\n",
    "        GRU_out = self.Self_Attention(outputs_GRU, batch_size)\n",
    "        context = torch.cat((GRU_out, pt_demo), 1)\n",
    "        linear_y = self.linear(context)\n",
    "        out = self.sigmoid(linear_y)\n",
    "        return linear_y,out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "import time\n",
    "EPOCHS = 200\n",
    "batch_size=24\n",
    "model=DBNet()\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "print(\"Starting Training of {} model\")\n",
    "\n",
    "epoch_times = []\n",
    "best_AUC=0\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    avg_loss = 0.\n",
    "    counter = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.train()\n",
    "    for sample in dataloader:\n",
    "        problem, lab, diag, orders,medAdmin,pt_demo,label = sample\n",
    "        model.zero_grad()\n",
    "        one_hot_label = np.eye(2)[np.array(label,dtype=\"int\")]\n",
    "        one_hot_label = torch.tensor(one_hot_label)\n",
    "        label= torch.tensor(label).type(torch.long)\n",
    "        problem = problem.to(device)\n",
    "        lab = lab.to(device)\n",
    "        diag = diag.to(device)\n",
    "        orders = orders.to(device)\n",
    "        medAdmin = medAdmin.to(device)\n",
    "        pt_demo = pt_demo.to(device)\n",
    "        counter += 1\n",
    "        out,predict=model(problem, lab, diag, orders,medAdmin, pt_demo,batch_size)\n",
    "        one_hot_label = one_hot_label.type_as(out).to(device)\n",
    "        loss = criterion(out, one_hot_label)\n",
    "        _, predicted = torch.max(predict.detach().cpu(), 1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item()\n",
    "    current_time = time.time()\n",
    "    print(\"Epoch {}/{} Done, Total Loss: {}, Accuracy : {} \".format(epoch, EPOCHS, avg_loss/len(dataloader),correct/total))\n",
    "    print(\"Total Time Elapsed: {} seconds\".format(str(current_time-start_time)))\n",
    "\n",
    "    epoch_times.append(current_time-start_time)\n",
    "    val_total=0\n",
    "    val_correct = 0\n",
    "    model.eval()\n",
    "    predicted_list=[]\n",
    "    prediction_probablity=[]\n",
    "    label_list = []\n",
    "    for sample in validation_loader:\n",
    "        problem, lab, diag, orders,medAdmin, pt_demo,label = sample\n",
    "        #model.zero_grad()\n",
    "        label= torch.tensor(label).type(torch.long)\n",
    "        problem = problem.to(device)\n",
    "        lab = lab.to(device)\n",
    "        diag = diag.to(device)\n",
    "        orders = orders.to(device)\n",
    "        medAdmin = medAdmin.to(device)\n",
    "        pt_demo = pt_demo.to(device)\n",
    "        out,predict=model(problem, lab, diag, orders,medAdmin, pt_demo,batch_size)\n",
    "        _, predicted = torch.max(predict.detach().cpu(), 1)\n",
    "        predicted_list.append(predicted.cpu().numpy())\n",
    "        predicted_2 = predict.detach().cpu().numpy()\n",
    "        prediction_prob = predicted_2[:,1]\n",
    "        prediction_probablity.append(prediction_prob)\n",
    "        label_list.append(label.cpu().numpy())\n",
    "        val_total += label.size(0)\n",
    "        val_correct += (predicted == label).sum().item()\n",
    "    Accuracy = val_correct/val_total\n",
    "    y=np.array(label_list)\n",
    "    false_positive_rate, recall, thresholds = roc_curve(y.flatten(), np.array(prediction_probablity).flatten())\n",
    "    roc_auc = auc(false_positive_rate, recall)\n",
    "    if roc_auc > best_AUC:\n",
    "        best_AUC = roc_auc\n",
    "        torch.save(model.state_dict(), \"Models_saved/State_checkpoints_{}.thr\".format(epoch))\n",
    "        torch.save(model, \"Models_saved/Model_checkpoints_{}.thr\".format(epoch))\n",
    "    print(\"AUC: {} , Accuracy: {}\".format(roc_auc,Accuracy))\n",
    "print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
